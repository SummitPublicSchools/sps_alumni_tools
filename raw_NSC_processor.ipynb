{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Raw NSC files to Warehouse\n",
    "\n",
    "This notebook executes the following actions:\n",
    "1. Uploads the NSC files to Drive. This includes the contents of the zipped folder.\n",
    "2. Upload the CSV file to the warehouse\n",
    "3. Process the uploaded data to `public.college_enrollments` and `public.college_degrees`\n",
    "\n",
    "## Make sure the CSV is raw\n",
    "Do **NOT** open the CSV and hit save prior to running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from spswarehouse.warehouse import Warehouse\n",
    "from spswarehouse.googledrive import GoogleDrive\n",
    "from spswarehouse.table_utils import *\n",
    "\n",
    "Warehouse.execute(\"USE ROLE dataops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "It's easiest to move the two files from NSC into the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below format assumes you moved the two NSC files to this directory\n",
    "excel_file_path = '10055266hsst_10055266-165967-DETAIL-EFFDT-20230427-RUNDT-20230602.csv'\n",
    "zip_file_path = '10055266hsst_10055266_EFFDT_20230427_RUNDT_20230602083733363.zip'\n",
    "\n",
    "# The \"as of\" date for the NSC file. The NSC file name contains two dates - this is the first date.\n",
    "# (The second date is the day the file was generated, but it's still a snapshot as of the first date)\n",
    "nsc_date = '2023-08-17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of all available NSC data in the warehouse, with underscores\n",
    "# Add the date you are working on right now\n",
    "list_of_all_nsc_dates = [\n",
    "    '2023_08_17',\n",
    "    '2023_04_27',\n",
    "    '2022_12_05',\n",
    "    '2022_08_30',\n",
    "    '2022_04_21',\n",
    "    '2021_04_16',\n",
    "    '2020_04_22',\n",
    "    '2020_09_18',\n",
    "    '2019_04_15',\n",
    "    '2019_11_25',\n",
    "    '2019_08_17',\n",
    "    '2018_11_28',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permanent Setup\n",
    "These variables should not change with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyphens in warehouse table names are big PITA\n",
    "date_underscored = nsc_date.replace(\"-\", \"_\")\n",
    "\n",
    "schema = 'national_student_clearinghouse'\n",
    "raw_table = 'raw_data_' + date_underscored\n",
    "clean_table = 'clean_data_' + date_underscored\n",
    "\n",
    "clean_table_sql_file = './Warehouse_SQL/raw_to_clean_nsc_python.sql'\n",
    "enrollment_sql_file = './Warehouse_SQL/public_enrollments_python.sql'\n",
    "degree_sql_file = './Warehouse_SQL/public_degrees_python.sql'\n",
    "\n",
    "# NSC files permanent home is https://drive.google.com/drive/folders/1Y3bSyRHwceFmsNYbo9vd59UXEtZHpj99\n",
    "alumni_folder_id = '1Y3bSyRHwceFmsNYbo9vd59UXEtZHpj99'\n",
    "\n",
    "# Number of days between enrollment records to indicate a dropout\n",
    "# Must be long enough to account for summer\n",
    "enrollment_gap = 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UploadFileToDrive(filename, parent_folder_id):\n",
    "    upload_file = GoogleDrive.CreateFile({\n",
    "        'title': filename,\n",
    "        'parents': [{\"kind\": \"drive#fileLink\", \"id\": parent_folder_id}],\n",
    "    })\n",
    "    upload_file.SetContentFile(filename)\n",
    "    upload_file.Upload()\n",
    "    return upload_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload files to Drive\n",
    "\n",
    "## Extract all files from the zip folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = 'data'\n",
    "\n",
    "nsc_zip = ZipFile('./' + zip_file_path)\n",
    "\n",
    "# Note: you can skip os.makedir because extractall creates the given path if it doesn't exist\n",
    "nsc_zip.extractall(temp_dir)\n",
    "\n",
    "nsc_zip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve list of CEEB codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceeb_sql = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    site_short_name\n",
    "    , ceeb_code\n",
    "FROM public.sites_historical\n",
    "\"\"\"\n",
    "\n",
    "sites_df = Warehouse.read_sql(ceeb_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Drive folder for this upload, upload raw data files there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = nsc_date + '_nsc_files'\n",
    "\n",
    "newFolder = GoogleDrive.CreateFile({\n",
    "    'title': folder_name,\n",
    "    \"parents\": [{\"kind\": \"drive#fileLink\", \"id\": alumni_folder_id}],\n",
    "    \"mimeType\": \"application/vnd.google-apps.folder\"\n",
    "})\n",
    "\n",
    "newFolder.Upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_drive_file = UploadFileToDrive(excel_file_path, newFolder['id'])\n",
    "UploadFileToDrive(zip_file_path, newFolder['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_list = os.listdir()\n",
    "for file_name in zip_file_list:\n",
    "    if 'ACADEMICS' in file_name:\n",
    "        os.remove(file_name)\n",
    "        continue\n",
    "\n",
    "    if file_name[22:24] == 'HS':\n",
    "        ceeb_code = file_name[24:30]\n",
    "        site_name = sites_df[sites_df['ceeb_code']==ceeb_code]['site_short_name'].iloc[0]\n",
    "        os.rename(file_name, site_name + file_name[37:])\n",
    "    else:\n",
    "        os.rename(file_name, 'Network' + file_name[37:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload renamed files to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload re-named files\n",
    "upload_file_list = os.listdir()\n",
    "for file_name in upload_file_list:\n",
    "    file_upload = UploadFileToDrive(file_name, newFolder['id'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might not work - I can't seem to close the connection to the last file uploaded\n",
    "# If it doesn't, manually delete the `data` folder and the two NSC files from the folder\n",
    "\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_file_id = csv_drive_file['id']\n",
    "\n",
    "Warehouse.execute(\"USE ROLE dataops\")\n",
    "\n",
    "create_sql = create_table_stmt(raw_table, schema, google_drive_id=drive_file_id, force_string=True, encoding='latin-1')\n",
    "Warehouse.execute(create_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_reflect = Warehouse.reflect(raw_table, schema)\n",
    "\n",
    "upload_to_warehouse(table_reflect, google_drive_id=drive_file_id, force_string=True, encoding= 'latin-1', batch_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Cleaned Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_table_sql = open(clean_table_sql_file).read()\n",
    "\n",
    "formatted_clean_sql = clean_table_sql.format(\n",
    "    clean_table=clean_table,\n",
    "    enrollment_gap=enrollment_gap,\n",
    "    raw_table=raw_table,\n",
    "    schema=schema,\n",
    "    update_date=nsc_date,\n",
    ")\n",
    "Warehouse.execute(formatted_clean_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refresh public tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public.college_enrollments\n",
    "\n",
    "# Create the series of statements for the UNION\n",
    "enrollment_union_sql = \"\"\n",
    "\n",
    "for upload_date in list_of_all_nsc_dates:\n",
    "    sql = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {schema}.clean_data_{upload_date}\n",
    "    UNION\"\"\"\n",
    "    \n",
    "    enrollment_union_sql += sql\n",
    "    \n",
    "enrollment_sql = open(enrollment_sql_file).read()\n",
    "formatted_enrollment_sql = enrollment_sql.format(\n",
    "    union_sql=enrollment_union_sql\n",
    ")\n",
    "\n",
    "Warehouse.execute(formatted_enrollment_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public.college_degrees\n",
    "\n",
    "# Create the series of statements for the UNION\n",
    "degree_union_sql = \"\"\n",
    "\n",
    "for upload_date in list_of_all_nsc_dates:\n",
    "    upload_date_hyphens = upload_date.replace('_', '-')\n",
    "    sql = f\"\"\"\n",
    "    SELECT *, '{upload_date_hyphens}' AS date_last_updated\n",
    "    FROM {schema}.raw_data_{upload_date}\n",
    "    UNION\"\"\"\n",
    "    \n",
    "    degree_union_sql += sql\n",
    "    \n",
    "degree_sql = open(degree_sql_file).read()\n",
    "formatted_degree_sql = degree_sql.format(\n",
    "    union_sql=degree_union_sql\n",
    ")\n",
    "\n",
    "Warehouse.execute(formatted_degree_sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
