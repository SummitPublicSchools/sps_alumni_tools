{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Raw NSC files to Warehouse\n",
    "\n",
    "This notebook executes the following actions:\n",
    "1. Uploads the NSC files to Drive. This includes the contents of the zipped folder.\n",
    "2. Upload the CSV file to the warehouse\n",
    "3. Process the uploaded data to `public.college_enrollments` and `public.college_degrees`\n",
    "\n",
    "## Make sure the CSV is raw\n",
    "Do **NOT** open the CSV and hit save prior to running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To access your Google Drive file, share the file with jupyter-sheets@sps-warehouse.iam.gserviceaccount.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<sqlalchemy.engine.base.Connection at 0x18f716dea30>,\n",
       " <sqlalchemy.engine.cursor.LegacyCursorResult at 0x18f76ad0d90>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from spswarehouse.warehouse import Warehouse\n",
    "from spswarehouse.googledrive import GoogleDrive\n",
    "from spswarehouse.table_utils import *\n",
    "\n",
    "Warehouse.execute(\"USE ROLE dataops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "It's easiest to move the two files from NSC into the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below format assumes you moved the two NSC files to this directory\n",
    "excel_file_path = '10055266hsst_10055266-186540-DETAIL-EFFDT-20240821-RUNDT-20240905.csv'\n",
    "zip_file_path = '10055266hsst_10055266_EFFDT_20240821_RUNDT_20240905143257301.zip'\n",
    "\n",
    "# The \"as of\" date for the NSC file. The NSC file name contains two dates - this is the first date.\n",
    "# (The second date is the day the file was generated, but it's still a snapshot as of the first date)\n",
    "nsc_date = '2024-08-21'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of all available NSC data in the warehouse, with underscores\n",
    "# Add the date you are working on right now\n",
    "list_of_all_nsc_dates = [\n",
    "    '2024_08_21',\n",
    "    '2024_04_03',\n",
    "    '2023_08_17',\n",
    "    '2023_04_27',\n",
    "    '2022_12_05',\n",
    "    '2022_08_30',\n",
    "    '2022_04_21',\n",
    "    '2021_04_16',\n",
    "    '2020_04_22',\n",
    "    '2020_09_18',\n",
    "    '2019_04_15',\n",
    "    '2019_11_25',\n",
    "    '2019_08_17',\n",
    "    '2018_11_28',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permanent Setup\n",
    "These variables should not change with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyphens in warehouse table names are big PITA\n",
    "date_underscored = nsc_date.replace(\"-\", \"_\")\n",
    "\n",
    "schema = 'national_student_clearinghouse'\n",
    "raw_table = 'raw_data_' + date_underscored\n",
    "clean_table = 'clean_data_' + date_underscored\n",
    "\n",
    "clean_table_sql_file = './Warehouse_SQL/raw_to_clean_nsc_python.sql'\n",
    "enrollment_sql_file = './Warehouse_SQL/public_enrollments_python.sql'\n",
    "degree_sql_file = './Warehouse_SQL/public_degrees_python.sql'\n",
    "\n",
    "# NSC files permanent home is https://drive.google.com/drive/folders/1Y3bSyRHwceFmsNYbo9vd59UXEtZHpj99\n",
    "alumni_folder_id = '1Y3bSyRHwceFmsNYbo9vd59UXEtZHpj99'\n",
    "\n",
    "# Number of days between enrollment records to indicate a dropout\n",
    "# Must be long enough to account for summer\n",
    "enrollment_gap = 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UploadFileToDrive(filename, parent_folder_id):\n",
    "    upload_file = GoogleDrive.CreateFile({\n",
    "        'title': filename,\n",
    "        'parents': [{\"kind\": \"drive#fileLink\", \"id\": parent_folder_id}],\n",
    "    })\n",
    "    upload_file.SetContentFile(filename)\n",
    "    upload_file.Upload()\n",
    "    return upload_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload files to Drive\n",
    "\n",
    "## Extract all files from the zip folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zip_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ead79c8801e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtemp_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnsc_zip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mzip_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Note: you can skip os.makedir because extractall creates the given path if it doesn't exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zip_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "temp_dir = 'data'\n",
    "\n",
    "nsc_zip = ZipFile('./' + zip_file_path)\n",
    "\n",
    "# Note: you can skip os.makedir because extractall creates the given path if it doesn't exist\n",
    "nsc_zip.extractall(temp_dir)\n",
    "\n",
    "nsc_zip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve list of CEEB codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ceeb_sql = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    site_short_name\n",
    "    , ceeb_code\n",
    "FROM public.sites_historical\n",
    "\"\"\"\n",
    "\n",
    "sites_df = Warehouse.read_sql(ceeb_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Drive folder for this upload, upload raw data files there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = nsc_date + '_nsc_files'\n",
    "\n",
    "newFolder = GoogleDrive.CreateFile({\n",
    "    'title': folder_name,\n",
    "    \"parents\": [{\"kind\": \"drive#fileLink\", \"id\": alumni_folder_id}],\n",
    "    \"mimeType\": \"application/vnd.google-apps.folder\"\n",
    "})\n",
    "\n",
    "newFolder.Upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zip_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-900516aa8ab7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcsv_drive_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUploadFileToDrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexcel_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewFolder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mUploadFileToDrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewFolder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'zip_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "csv_drive_file = UploadFileToDrive(excel_file_path, newFolder['id'])\n",
    "UploadFileToDrive(zip_file_path, newFolder['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b6eb90b0ae4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'data'"
     ]
    }
   ],
   "source": [
    "os.chdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_list = os.listdir()\n",
    "for file_name in zip_file_list:\n",
    "    if 'ACADEMICS' in file_name:\n",
    "        os.remove(file_name)\n",
    "        continue\n",
    "\n",
    "    if file_name[22:24] == 'HS':\n",
    "        ceeb_code = file_name[24:30]\n",
    "        site_name = sites_df[sites_df['ceeb_code']==ceeb_code]['site_short_name'].iloc[0]\n",
    "        os.rename(file_name, site_name + file_name[37:])\n",
    "    else:\n",
    "        os.rename(file_name, 'Network' + file_name[37:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload renamed files to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload re-named files\n",
    "upload_file_list = os.listdir()\n",
    "for file_name in upload_file_list:\n",
    "    file_upload = UploadFileToDrive(file_name, newFolder['id'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fe2f50aa5246>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# If it doesn't, manually delete the `data` folder and the two NSC files from the folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;31m# can't continue even if onerror hook returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m         \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscandir_it\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m             \u001b[0mentries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscandir_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "# Verify that you are where you think you are!\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might not work - I can't seem to close the connection to the last file uploaded\n",
    "# If it doesn't, manually delete the `data` folder and the two NSC files from the folder\n",
    "shutil.rmtree('./' + temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<sqlalchemy.engine.base.Connection at 0x18f716dea30>,\n",
       " <sqlalchemy.engine.cursor.LegacyCursorResult at 0x18f76d5eee0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_file_id = csv_drive_file['id']\n",
    "\n",
    "Warehouse.execute(\"USE ROLE dataops\")\n",
    "\n",
    "create_sql = create_table_stmt(raw_table, schema, google_drive_id=drive_file_id, force_string=True, encoding='latin-1')\n",
    "Warehouse.execute(create_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28933 rows to insert\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 2000 rows to national_student_clearinghouse.raw_data_2024_04_03\n",
      "Inserted 933 rows to national_student_clearinghouse.raw_data_2024_04_03\n"
     ]
    }
   ],
   "source": [
    "table_reflect = Warehouse.reflect(raw_table, schema)\n",
    "\n",
    "upload_to_warehouse(table_reflect, google_drive_id=drive_file_id, force_string=True, encoding= 'latin-1', batch_size=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Cleaned Data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<sqlalchemy.engine.base.Connection at 0x18f716dea30>,\n",
       " <sqlalchemy.engine.cursor.LegacyCursorResult at 0x18f76f014c0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_table_sql = open(clean_table_sql_file).read()\n",
    "\n",
    "formatted_clean_sql = clean_table_sql.format(\n",
    "    clean_table=clean_table,\n",
    "    enrollment_gap=enrollment_gap,\n",
    "    raw_table=raw_table,\n",
    "    schema=schema,\n",
    "    update_date=nsc_date,\n",
    ")\n",
    "Warehouse.execute(formatted_clean_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refresh public tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<sqlalchemy.engine.base.Connection at 0x18f716dea30>,\n",
       " <sqlalchemy.engine.cursor.LegacyCursorResult at 0x18f76f01040>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# public.college_enrollments\n",
    "\n",
    "# Create the series of statements for the UNION\n",
    "enrollment_union_sql = \"\"\n",
    "\n",
    "for upload_date in list_of_all_nsc_dates:\n",
    "    sql = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {schema}.clean_data_{upload_date}\n",
    "    UNION\"\"\"\n",
    "    \n",
    "    enrollment_union_sql += sql\n",
    "    \n",
    "enrollment_sql = open(enrollment_sql_file).read()\n",
    "formatted_enrollment_sql = enrollment_sql.format(\n",
    "    union_sql=enrollment_union_sql\n",
    ")\n",
    "\n",
    "Warehouse.execute(formatted_enrollment_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<sqlalchemy.engine.base.Connection at 0x18f716dea30>,\n",
       " <sqlalchemy.engine.cursor.LegacyCursorResult at 0x18f76f01610>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# public.college_degrees\n",
    "\n",
    "# Create the series of statements for the UNION\n",
    "degree_union_sql = \"\"\n",
    "\n",
    "for upload_date in list_of_all_nsc_dates:\n",
    "    upload_date_hyphens = upload_date.replace('_', '-')\n",
    "    sql = f\"\"\"\n",
    "    SELECT *, '{upload_date_hyphens}' AS date_last_updated\n",
    "    FROM {schema}.raw_data_{upload_date}\n",
    "    UNION\"\"\"\n",
    "    \n",
    "    degree_union_sql += sql\n",
    "    \n",
    "degree_sql = open(degree_sql_file).read()\n",
    "formatted_degree_sql = degree_sql.format(\n",
    "    union_sql=degree_union_sql\n",
    ")\n",
    "\n",
    "Warehouse.execute(formatted_degree_sql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
